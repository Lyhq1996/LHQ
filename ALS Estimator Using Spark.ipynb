{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1: ALS Estimator Using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: apt-get: command not found\n",
      "/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java has not been configured as an alternative for java\n",
      "openjdk version \"1.8.0_152-release\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12)\n",
      "OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode)\n",
      "Python 3.6.5 :: Anaconda, Inc.\n"
     ]
    }
   ],
   "source": [
    "#!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www-eu.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
    "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
    "\n",
    "!pip install -q findspark\n",
    "#!pip install pyspark\n",
    "\n",
    "# Set up required environment variables\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/drive/My Drive/spark-2.4.5-bin-hadoop2.7\"\n",
    "\n",
    "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
    "\n",
    "!java -version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[*] appName=pyspark-shell>\n",
      "<pyspark.sql.session.SparkSession object at 0x7f05a20c0160>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#install spark\n",
    "#!pip install pyspark\n",
    "import pyspark\n",
    " # get a spark context\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "print(sc)\n",
    "# and a spark session\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "print(spark)\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"spark-2.4.5-bin-hadoop2.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|              Comedy|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "|     1|     70|   3.0|964982400|\n",
      "|     1|    101|   5.0|964980868|\n",
      "|     1|    110|   4.0|964982176|\n",
      "|     1|    151|   5.0|964984041|\n",
      "|     1|    157|   5.0|964984100|\n",
      "|     1|    163|   5.0|964983650|\n",
      "|     1|    216|   5.0|964981208|\n",
      "|     1|    223|   3.0|964980985|\n",
      "|     1|    231|   5.0|964981179|\n",
      "|     1|    235|   4.0|964980908|\n",
      "|     1|    260|   5.0|964981680|\n",
      "|     1|    296|   3.0|964982967|\n",
      "|     1|    316|   3.0|964982310|\n",
      "|     1|    333|   5.0|964981179|\n",
      "|     1|    349|   4.0|964982563|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#step 2: load data\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "# the imports are used creating the data frame\n",
    "\n",
    "# create a SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()  \n",
    "\n",
    "\n",
    "data_movie=pd.read_csv(\"movies.csv\")\n",
    "df_movie=spark.createDataFrame(data_movie)\n",
    "df_movie.show()\n",
    "\n",
    "data_ratings=pd.read_csv(\"ratings.csv\")\n",
    "df_ratings=spark.createDataFrame(data_ratings)\n",
    "df_ratings.show()\n",
    "\n",
    "df_ratings.createOrReplaceTempView('ratings') \n",
    "df_movie.createOrReplaceTempView('movie') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: long (nullable = true)\n",
      " |-- movieId: long (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      "\n",
      "80692\n",
      "20144\n"
     ]
    }
   ],
   "source": [
    "(training, test) = df_ratings.randomSplit([0.8, 0.2]) # split into test and training set\n",
    "training.printSchema() # just for testing, should show the four columns\n",
    "print(training.count()) # just for testing, should be around 1200\n",
    "print(test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanRating 3.501556983616962\n",
      "se_df DataFrame[se: double]\n",
      "RMSE 1.042255274433242\n"
     ]
    }
   ],
   "source": [
    "##step2: create a baseline\n",
    "SQL1 = 'SELECT AVG(rating) FROM ratings'\n",
    "row = spark.sql(SQL1).collect()[0] # get the single row with the result\n",
    "\n",
    "meanRating = row['avg(rating)'] # access Row as a map \n",
    "print('meanRating',meanRating)\n",
    "\n",
    "se_rdd = test.rdd.map(lambda row: Row(se = pow(row['rating']-meanRating,2)) ) \n",
    "se_df = spark.createDataFrame(se_rdd) \n",
    "se_df.createOrReplaceTempView('se')\n",
    "print('se_df',se_df)\n",
    "SQL2 = 'SELECT AVG(se) FROM se'\n",
    "row = spark.sql(SQL2).collect()[0]\n",
    "meanSE = row['avg(se)'] # access Row as a map \n",
    "print('RMSE',pow(meanSE,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting cross-validation\n",
      "finished cross-validation\n"
     ]
    }
   ],
   "source": [
    "##step3:train ALS estimator and perform CV\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=3, rank=10, regParam=0.1, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",coldStartStrategy=\"drop\")\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "  .addGrid(als.regParam, [0.03,0.1,0.3]) \\\n",
    "  .addGrid(als.rank, [3,10,30]).build()\n",
    "\n",
    "regEval = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "crossVal = CrossValidator(estimator=als, estimatorParamMaps=paramGrid, evaluator=regEval)\n",
    "print('starting cross-validation')\n",
    "cvModel = crossVal.fit(training)\n",
    "print('finished cross-validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0407429967801038, 1.1286802586942164, 1.2243138199626695, 0.9565689384360606, 0.9675925202230801, 0.9511332209407668, 0.9468515116188687, 0.9542613945302745, 0.960822201414864]\n",
      "[{Param(parent='ALS_43eb84313eccbbc282f9', name='regParam', doc='regularization parameter (>= 0).'): 0.03, Param(parent='ALS_43eb84313eccbbc282f9', name='rank', doc='rank of the factorization'): 3}, {Param(parent='ALS_43eb84313eccbbc282f9', name='regParam', doc='regularization parameter (>= 0).'): 0.03, Param(parent='ALS_43eb84313eccbbc282f9', name='rank', doc='rank of the factorization'): 10}, {Param(parent='ALS_43eb84313eccbbc282f9', name='regParam', doc='regularization parameter (>= 0).'): 0.03, Param(parent='ALS_43eb84313eccbbc282f9', name='rank', doc='rank of the factorization'): 30}, {Param(parent='ALS_43eb84313eccbbc282f9', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='ALS_43eb84313eccbbc282f9', name='rank', doc='rank of the factorization'): 3}, {Param(parent='ALS_43eb84313eccbbc282f9', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='ALS_43eb84313eccbbc282f9', name='rank', doc='rank of the factorization'): 10}, {Param(parent='ALS_43eb84313eccbbc282f9', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='ALS_43eb84313eccbbc282f9', name='rank', doc='rank of the factorization'): 30}, {Param(parent='ALS_43eb84313eccbbc282f9', name='regParam', doc='regularization parameter (>= 0).'): 0.3, Param(parent='ALS_43eb84313eccbbc282f9', name='rank', doc='rank of the factorization'): 3}, {Param(parent='ALS_43eb84313eccbbc282f9', name='regParam', doc='regularization parameter (>= 0).'): 0.3, Param(parent='ALS_43eb84313eccbbc282f9', name='rank', doc='rank of the factorization'): 10}, {Param(parent='ALS_43eb84313eccbbc282f9', name='regParam', doc='regularization parameter (>= 0).'): 0.3, Param(parent='ALS_43eb84313eccbbc282f9', name='rank', doc='rank of the factorization'): 30}]\n",
      "({Param(parent='ALS_43eb84313eccbbc282f9', name='regParam', doc='regularization parameter (>= 0).'): 0.3, Param(parent='ALS_43eb84313eccbbc282f9', name='rank', doc='rank of the factorization'): 3}, 0.9468515116188687)\n",
      "RMSE = 0.9203927102470062\n"
     ]
    }
   ],
   "source": [
    "print(cvModel.avgMetrics) # the metrics form the CrossValidation\n",
    "print(cvModel.getEstimatorParamMaps()) # gives you the parameter combinations\n",
    "paramMap = list(zip(cvModel.getEstimatorParamMaps(),cvModel.avgMetrics))\n",
    "paramMin = min(paramMap, key=lambda x: x[1])\n",
    "print(paramMin)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = cvModel.transform(test)\n",
    "rmse = regEval.evaluate(predictions)\n",
    "print(\"RMSE = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|   372|    471|   3.0| 874415126| 3.1767607|\n",
      "|   462|    471|   2.5|1123890831| 2.5841093|\n",
      "|   287|    471|   4.5|1110231536| 2.4000242|\n",
      "|    32|    471|   3.0| 856737165| 3.6538186|\n",
      "|   414|    471|   5.0| 961514069| 3.3663368|\n",
      "|   608|    471|   1.5|1117161794| 3.1839418|\n",
      "|   426|    471|   5.0|1451081135| 3.4786158|\n",
      "|   608|    833|   0.5|1117506344|  2.160833|\n",
      "|    20|   1088|   4.5|1054147512| 3.4739363|\n",
      "|    64|   1088|   4.0|1161559902| 3.4067392|\n",
      "|   583|   1088|   3.5|1481474480|  3.046348|\n",
      "|   555|   1088|   4.0| 978822670| 3.2257967|\n",
      "|   226|   1088|   1.0|1096420160| 3.2811496|\n",
      "|   483|   1088|   3.0|1215895737|  3.340597|\n",
      "|   517|   1088|   1.0|1487958398| 2.2894535|\n",
      "|   593|   1580|   1.5|1181007882|  2.870765|\n",
      "|    34|   1580|   2.5|1162048827|  3.187867|\n",
      "|   587|   1580|   4.0| 953138475| 3.5870633|\n",
      "|   577|   1580|   3.0| 945965825| 3.1090202|\n",
      "|    91|   1580|   3.5|1112711168| 3.1255634|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()\n",
    "predictions.createOrReplaceTempView('predictions') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|    11|      6|   5.0|902154266|\n",
      "|    11|     10|   3.0|902154316|\n",
      "|    11|     36|   4.0|902155135|\n",
      "|    11|     44|   2.0|902154593|\n",
      "|    11|     95|   3.0|902154458|\n",
      "|    11|    110|   5.0|902154266|\n",
      "|    11|    150|   5.0|902154266|\n",
      "|    11|    165|   3.0|902154567|\n",
      "|    11|    170|   4.0|902154621|\n",
      "|    11|    208|   3.0|902154706|\n",
      "|    11|    292|   4.0|902154383|\n",
      "|    11|    318|   4.0|902155070|\n",
      "|    11|    349|   5.0|902154342|\n",
      "|    11|    368|   3.0|904510567|\n",
      "|    11|    376|   2.0|902154684|\n",
      "|    11|    377|   3.0|902154431|\n",
      "|    11|    434|   3.0|902154685|\n",
      "|    11|    457|   5.0|902154316|\n",
      "|    11|    466|   3.0|902154805|\n",
      "|    11|    474|   4.0|902154431|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###for a specific user\n",
    "\n",
    "user_history = training.filter(training['userId']==11)\n",
    "user_history.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|movieId|userId|\n",
      "+-------+------+\n",
      "|    153|    11|\n",
      "|    356|    11|\n",
      "|    380|    11|\n",
      "|    593|    11|\n",
      "|   1370|    11|\n",
      "|   1408|    11|\n",
      "|   1552|    11|\n",
      "|   1584|    11|\n",
      "|   1693|    11|\n",
      "|   1918|    11|\n",
      "|   2027|    11|\n",
      "|   2028|    11|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a list of movies we are thinking to offer\n",
    "user_suggest = test.filter(training['userId']==11).select(['movieId', 'userId'])\n",
    "user_suggest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|movieId|userId|prediction|\n",
      "+-------+------+----------+\n",
      "|    593|    11|  4.205923|\n",
      "|    356|    11|  4.087714|\n",
      "|   2028|    11| 3.9526556|\n",
      "|   1584|    11| 3.6363184|\n",
      "|   1408|    11| 3.6256447|\n",
      "|   1370|    11|  3.483639|\n",
      "|    380|    11| 3.4523625|\n",
      "|   1693|    11| 3.3422816|\n",
      "|   1552|    11| 3.0669956|\n",
      "|    153|    11| 2.8908749|\n",
      "|   1918|    11|   2.69265|\n",
      "|   2027|    11| 1.8627541|\n",
      "+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# offer movies with a high predicted rating\n",
    "user_offer = cvModel.transform(user_suggest)\n",
    "user_offer.orderBy('prediction', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+---------+\n",
      "|userId|movieId|               title|  maxpred|\n",
      "+------+-------+--------------------+---------+\n",
      "|     1|   1927|All Quiet on the ...|   4.7581|\n",
      "|     2|  48516|Departed, The (2006)|3.8582234|\n",
      "|     3|   5048|    Snow Dogs (2002)|2.0995681|\n",
      "|     4|    599|Wild Bunch, The (...| 3.780693|\n",
      "|     5|    608|        Fargo (1996)|3.8461504|\n",
      "|     6|     47|Seven (a.k.a. Se7...|3.7696934|\n",
      "|     7|  38388|Goal! The Dream B...|3.8658383|\n",
      "|     8|    318|Shawshank Redempt...|  4.05491|\n",
      "|     9|   5965|Duellists, The (1...|3.9293904|\n",
      "|    10|   2959|   Fight Club (1999)|3.5206406|\n",
      "|    11|    593|Silence of the La...| 4.205923|\n",
      "|    12|    222|Circle of Friends...|4.5654244|\n",
      "|    13|     47|Seven (a.k.a. Se7...| 3.706434|\n",
      "|    14|    356| Forrest Gump (1994)|3.8502324|\n",
      "|    15|    527|Schindler's List ...|3.5272605|\n",
      "|    16|   3022| General, The (1926)|  4.09401|\n",
      "|    17|   1201|Good, the Bad and...|4.2333884|\n",
      "|    18|   6300|Flickering Lights...|4.1854224|\n",
      "|    19|    930|    Notorious (1946)| 3.249547|\n",
      "|    20|    720|Wallace & Gromit:...|4.1959996|\n",
      "+------+-------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.createOrReplaceTempView('training') \n",
    "df_movie.createOrReplaceTempView('movies') \n",
    "\n",
    "rec_table = '''SELECT C.userId,predictions.movieId,C.maxpred FROM predictions,\n",
    "        (SELECT MAX(prediction) AS maxpred,userId FROM predictions WHERE userId IN (SELECT userId FROM training) GROUP BY userId) C\n",
    "        WHERE predictions.prediction=C.maxpred'''\n",
    "\n",
    "spark.sql(pred_table).createOrReplaceTempView('rec_table') \n",
    "\n",
    "rec_with_title='''SELECT P.userId,P.movieId,M.title,P.maxpred \n",
    "                FROM rec_table P,movies M WHERE M.movieId=P.movieId\n",
    "                ORDER BY P.userId ASC '''\n",
    "spark.sql(rec_with_title).show()\n",
    "spark.sql(rec_with_title).createOrReplaceTempView('rec_table_with_title') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: AWS SageMaker Factorization Machines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-12 21:10:12--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4924029 (4.7M) [application/zip]\n",
      "Saving to: ‘ml-100k.zip’\n",
      "\n",
      "ml-100k.zip         100%[===================>]   4.70M  11.1MB/s    in 0.4s    \n",
      "\n",
      "2020-04-12 21:10:13 (11.1 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
      "\n",
      "Archive:  ml-100k.zip\n",
      "   creating: ml-100k/\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    }
   ],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/ml-100k\n",
      "189\t661\t4\t893265569\n",
      "374\t38\t4\t880937876\n",
      "83\t692\t4\t880307979\n",
      "249\t456\t3\t879640549\n",
      "327\t523\t4\t887818800\n",
      "479\t177\t4\t889125665\n",
      "472\t780\t4\t875982922\n",
      "805\t831\t4\t881695040\n",
      "846\t601\t5\t883947500\n",
      "144\t961\t3\t888106106\n"
     ]
    }
   ],
   "source": [
    "%cd ml-100k\n",
    "!shuf ua.base -o ua.base.shuffled\n",
    "!head -10 ua.base.shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t20\t4\t887431883\r\n",
      "1\t33\t4\t878542699\r\n",
      "1\t61\t4\t878542420\r\n",
      "1\t117\t3\t874965739\r\n",
      "1\t155\t2\t878542201\r\n",
      "1\t160\t4\t875072547\r\n",
      "1\t171\t5\t889751711\r\n",
      "1\t189\t3\t888732928\r\n",
      "1\t202\t5\t875072442\r\n",
      "1\t265\t4\t878542441\r\n"
     ]
    }
   ],
   "source": [
    "!head -10 ua.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import json_deserializer\n",
    "\n",
    "import boto3, csv, io, json\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
